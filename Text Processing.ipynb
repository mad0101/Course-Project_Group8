{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import TFBertTokenizer\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import torch.nn as nn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"uncleaned_combined_txt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My autistic 3 year old said her first sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>From having the left side of my lips almost co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>After dating for just over two years, I propos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>One day at a time. Smiling more makes a big di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>trying my hardest to be happy today. I hope my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1</td>\n",
       "      <td>death sound appealingthought death thing bring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1</td>\n",
       "      <td>left relationship almost 5 years depression en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1</td>\n",
       "      <td>always wanted friendlife never anyone loved ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>1</td>\n",
       "      <td>deal someone avoids everythinghi close friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>1</td>\n",
       "      <td>turns might depressedhey became orphan cry hon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  My autistic 3 year old said her first sentence...\n",
       "1         0  From having the left side of my lips almost co...\n",
       "2         0  After dating for just over two years, I propos...\n",
       "3         0  One day at a time. Smiling more makes a big di...\n",
       "4         0  trying my hardest to be happy today. I hope my...\n",
       "...     ...                                                ...\n",
       "1759      1  death sound appealingthought death thing bring...\n",
       "1760      1  left relationship almost 5 years depression en...\n",
       "1761      1  always wanted friendlife never anyone loved ca...\n",
       "1762      1  deal someone avoids everythinghi close friend ...\n",
       "1763      1  turns might depressedhey became orphan cry hon...\n",
       "\n",
       "[1764 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing funciton created\n",
    "def preprocessing(df):\n",
    "    df1 = df.copy()\n",
    "    df1['white_space_removed'] = 0\n",
    "    df1['numbers_removed']=0\n",
    "    df1['url_removed_data'] = 0\n",
    "    df1['user_removed'] = 0\n",
    "    df1['emoji_removed'] = 0\n",
    "    df1['tokenized_data'] = 0\n",
    "    df1['stopword_removed_data'] = 0\n",
    "    df1['punct_removed_data'] = 0\n",
    "    df1['spelling_checked_data'] = 0\n",
    "    df1['lemma_data'] = 0\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "#   lemmatizer = WordNetLemmatizer()\n",
    "    spell = Speller(lang='en')\n",
    "\n",
    "\n",
    "  # iterate over each row of dataset and preprocess data\n",
    "    for i in tqdm(range(df1.shape[0])):\n",
    "\n",
    "        # white space removel\n",
    "        df1['white_space_removed'][i] = re.sub(\"\\s+\", \" \", df1.text[i])\n",
    "        df1['url_removed_data'][i] = re.sub('(www|http)\\S+',\" \",df1['white_space_removed'][i])\n",
    "        df1['user_removed'][i] = re.sub('^@\\S+',\" \",df1['url_removed_data'][i])\n",
    "        df1['numbers_removed'][i] = re.sub('\\d+','',df1['user_removed'][i])\n",
    "        emoji_removed = re.sub(r'\\W+', ' ', df1['numbers_removed'][i].encode('ascii', 'ignore').decode('utf-8'), flags=re.UNICODE).strip()\n",
    "        df1['emoji_removed'][i] = emoji_removed\n",
    "\n",
    "        # lower casing and tokenization\n",
    "        lower = df1['emoji_removed'][i].lower()\n",
    "        tokenized_data = word_tokenize(lower)\n",
    "        df1['tokenized_data'][i] = tokenized_data\n",
    "        # print(tokenized_data)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # remove stopwords\n",
    "        stopword_removed_data = [x for x in tokenized_data if x not in stop_words]\n",
    "        df1['stopword_removed_data'][i] = stopword_removed_data \n",
    "        # print(stopword_removed_data)\n",
    "        \n",
    "        \n",
    "        # punctuation removal\n",
    "        punct_removed_data = [x for x in stopword_removed_data if x.isalnum()]\n",
    "        df1['punct_removed_data'][i] = punct_removed_data\n",
    "        # print(punct_removed_data)\n",
    "        \n",
    "\n",
    "        spelling_checked_data = [spell(x) for x in punct_removed_data]\n",
    "        df1['spelling_checked_data'][i] = spelling_checked_data\n",
    "#         print(\" \".join(spelling_checked_data))\n",
    "\n",
    "        lemma_data = [lemma.lemmatize(x) for x in spelling_checked_data]\n",
    "        df1['lemma_data'][i] = \" \".join(lemma_data)\n",
    "\n",
    "        # spelling checking\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                    0\n",
       "text     My autistic 3 year old said her first sentence...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1764/1764 [06:42<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = preprocessing(data)\n",
    "preprocessed_data = preprocessed_data[preprocessed_data['lemma_data']!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['text', 'target'],index = None)\n",
    "df['text'] = preprocessed_data['lemma_data']\n",
    "df['target'] = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autistic year old said first sentence today ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left side lip almost completely torn face dog ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dating two year proposed said yes engaged</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one day time smiling make big difference</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying hardest happy today hope face brings so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>death sound appealingthought death thing bring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>left relationship almost year depression engul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>always wanted friendly never anyone loved care...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>deal someone avoids everything close friend le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>turn might depressedhey became orphan cry hone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1762 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     autistic year old said first sentence today ne...       0\n",
       "1     left side lip almost completely torn face dog ...       0\n",
       "2             dating two year proposed said yes engaged       0\n",
       "3              one day time smiling make big difference       0\n",
       "4     trying hardest happy today hope face brings so...       0\n",
       "...                                                 ...     ...\n",
       "1759  death sound appealingthought death thing bring...       1\n",
       "1760  left relationship almost year depression engul...       1\n",
       "1761  always wanted friendly never anyone loved care...       1\n",
       "1762  deal someone avoids everything close friend le...       1\n",
       "1763  turn might depressedhey became orphan cry hone...       1\n",
       "\n",
       "[1762 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data_all.csv\", index = False)\n",
    "cleaned_df = pd.read_csv(\"cleaned_data_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
